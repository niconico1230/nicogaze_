import torch
import torch.nn as nn
import numpy as np
from DATAeye import eyelist  # è¦–ç·šãƒ‡ãƒ¼ã‚¿ (æ™‚åˆ», x, y)
from DATAmoji import mojilist  # æ–‡ç« ã®å˜èªãƒ‡ãƒ¼ã‚¿ (æ–‡å­—, x, y)

# è¦–ç·šã¨å˜èªã®ãƒãƒƒãƒãƒ³ã‚°ï¼ˆè·é›¢ threshold ä»¥å†…ã®å˜èªã‚’å¯¾å¿œä»˜ã‘ã‚‹ï¼‰
def match_gaze_to_text(eyelist, mojilist, threshold=50):
    matched = []  
    for t, gx, gy in eyelist:
        min_dist = float("inf")
        closest_word = None
        for word, tx, ty in mojilist:
            dist = np.sqrt((gx - tx) ** 2 + (gy - ty) ** 2)
            if dist < threshold and dist < min_dist:
                min_dist = dist
                closest_word = (word, tx, ty)
        if closest_word:
            matched.append(((t, gx, gy), closest_word))
    return matched

# è¦–ç·šã¨å˜èªã®å¯¾å¿œä»˜ã‘
matched_pairs = match_gaze_to_text(eyelist, mojilist)

# è¦–ç·šãƒ‡ãƒ¼ã‚¿ (t, gx, gy) ã‚’ NumPy é…åˆ—ã«å¤‰æ›
gaze_data = np.array([[t, gx, gy] for (t, gx, gy), _ in matched_pairs])

# å¹³å‡0ãƒ»æ¨™æº–åå·®1ã«æ­£è¦åŒ–
time_mean = np.mean(gaze_data[:, 0])  # æ™‚é–“ (t) ã®å¹³å‡
time_std = np.std(gaze_data[:, 0])  # æ™‚é–“ (t) ã®æ¨™æº–åå·®
gaze_data[:, 0] = (gaze_data[:, 0] - time_mean) / time_std  # æ™‚é–“ t ã®æ­£è¦åŒ–

# **ãƒ‡ãƒ¼ã‚¿ã®ãƒ†ãƒ³ã‚½ãƒ«åŒ–**
gaze_seq = torch.tensor([[t, x, y] for (t, x, y), _ in matched_pairs], dtype=torch.float32)
text_seq = torch.tensor([[tx, ty] for (_, (word, tx, ty)) in matched_pairs], dtype=torch.float32)

# æ–‡å­—ã”ã¨ã®ç†æƒ³çš„ãªè¦–ç·šæ»åœ¨æ™‚é–“
importance = {"æ¯€": 1.0, "å—¤": 1.0}  # é‡è¦ãªæ–‡å­—ã«ã¯1.0ã€ãã‚Œä»¥å¤–ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ0.3
#target_times = torch.tensor([[importance.get(word, 0.3)] for (_, (word, _, _)) in matched_pairs], dtype=torch.float32)
target_times = [importance.get(word, 0.3) for (_, (word, _, _)) in matched_pairs]
target_times = torch.tensor(target_times, dtype=torch.float32).unsqueeze(0).unsqueeze(-1)  # [1, seq_len, 1]


# ãƒãƒƒãƒæ¬¡å…ƒã‚’è¿½åŠ 
gaze_seq = gaze_seq.unsqueeze(0)  # shape: [1, seq_len, 3]
text_seq = text_seq.unsqueeze(0)  # shape: [1, seq_len, 2]
#target_times = target_times.unsqueeze(0)  # shape: [1, seq_len, 1]

# **ãƒ¢ãƒ‡ãƒ«ã®å®šç¾©**
class GazeTextEncoder(nn.Module):
    def __init__(self, hidden_dim=32):
        super().__init__()
        self.lstm_gaze = nn.LSTM(3, hidden_dim, batch_first=True)
        self.lstm_text = nn.LSTM(2, hidden_dim, batch_first=True)
        self.output_layer = nn.Linear(hidden_dim, 1)  

    def forward(self, gaze_seq, text_seq):
        H_gaze, _ = self.lstm_gaze(gaze_seq)  # [1, seq_len, hidden_dim]
        H_text, _ = self.lstm_text(text_seq)  # [1, seq_len, hidden_dim]

        # ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³è¨ˆç®—
        H_gaze_t = H_gaze.transpose(1, 2)  # è»¢ç½®
        attn_scores = torch.bmm(H_text, H_gaze_t)  # [1, seq_len, seq_len]
        attn_weights = torch.softmax(torch.tanh(attn_scores), dim=-1)
        context = torch.bmm(attn_weights, H_gaze)  # [1, seq_len, hidden_dim]
        print(H_gaze)
        # è¦–ç·šæ»åœ¨æ™‚é–“ã®äºˆæ¸¬
        predicted_times = self.output_layer(context)  # [1, seq_len, 1]
        return predicted_times

# **å­¦ç¿’ã®æº–å‚™**
model = GazeTextEncoder()
optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)
loss_fn = nn.MSELoss()

# **å­¦ç¿’ãƒ«ãƒ¼ãƒ—**
for epoch in range(100):
    model.train()
    optimizer.zero_grad()
    outputs = model(gaze_seq, text_seq)
    loss = loss_fn(outputs, target_times)
    loss.backward()
    optimizer.step()

    if epoch % 10 == 0:
        print(f"Epoch {epoch}: Loss = {loss.item():.4f}")

# **äºˆæ¸¬ã®è¡¨ç¤ºï¼ˆæ–‡ç« é †ã«ä¸¦ã³æ›¿ãˆï¼‰**
model.eval()
with torch.no_grad():
    predicted = model(gaze_seq, text_seq)
    #print(predicted)

# å˜èªã”ã¨ã®äºˆæ¸¬å€¤ã‚’è¾æ›¸ã«æ ¼ç´
pred_dict = {word: value.item() for (_, (word, _, _)), value in zip(matched_pairs, predicted[0])}


# æ–‡ç« ã®æ–‡å­—é †ã§å‡ºåŠ›
print("\nğŸ“Š Predicted gaze times (per character in sentence order):")
for word, _, _ in mojilist:  # æ–‡ç« ã®é †ç•ªã§å‡ºåŠ›
    predicted_time = pred_dict.get(word, 0.0)  # è¦–ç·šãŒãƒãƒƒãƒã—ãªã‹ã£ãŸæ–‡å­—ã¯ 0.0
    print(f"{word}: {predicted_time:.3f}")