import torch
import torch.nn as nn
import numpy as np
from DATAeye import eyelist
from DATAmoji import mojilist


# ç©ºé–“çš„ã«è¿‘ã„ gaze ã¨æ–‡å­—ã‚’çµã³ã¤ã‘ã‚‹ï¼ˆä¾‹ï¼šè·é›¢ãŒä¸€å®šä»¥ä¸‹ï¼‰
# threshold: è¦–ç·šã¨å˜èªä½ç½®ã®ã€Œè¿‘ã•ã€ã‚’åˆ¤å®šã™ã‚‹ãŸã‚ã®è·é›¢ã®ã—ãã„å€¤
def match_gaze_to_text(eyelist, mojilist, threshold=50):
    matched = []  # çµæœã‚’ä¿å­˜ã™ã‚‹ãƒªã‚¹ãƒˆã‚’åˆæœŸåŒ– ã€Œè¦–ç·šã¨å¯¾å¿œã™ã‚‹å˜èªã€ã‚’ãƒšã‚¢ã§è¿½åŠ ã—ã¦ã„ãã¾ã™ã€‚
    for t, gx, gy in eyelist:  # è¦–ç·šãƒ‡ãƒ¼ã‚¿ã‚’1ã¤ãšã¤å–ã‚Šå‡ºã™
        min_dist = float("inf")  # æœ€å°è·é›¢ï¼ˆæœ€åˆã¯ç„¡é™å¤§ã«ã—ã¦ãŠãï¼‰
        closest_word = None  # æœ€ã‚‚è¿‘ã‹ã£ãŸå˜èªã‚’ã“ã“ã«ä¿æŒã™ã‚‹
        for word, tx, ty in mojilist:  # ã™ã¹ã¦ã®å˜èªã®ä½ç½®ã¨æ¯”è¼ƒã™ã‚‹ãƒ«ãƒ¼ãƒ—
            dist = np.sqrt((gx - tx)**2 + (gy - ty)**2)  # è¦–ç·šã¨ã®è·é›¢ã‚’è¨ˆç®—ï¼ˆãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢ï¼‰
            if dist < threshold and dist < min_dist:
                min_dist = dist
                closest_word = (word, tx, ty)
        if closest_word:  # è¦‹ã¤ã‹ã£ãŸæœ€ã‚‚è¿‘ã„å˜èªãŒã‚ã‚Œã°
            matched.append(((t, gx, gy), closest_word))  # ãã®è¦–ç·šã¨å˜èªã‚’ãƒšã‚¢ã§è¿½åŠ 
    return matched

matched_pairs = match_gaze_to_text(eyelist, mojilist)

# gazeå…¥åŠ›: æ™‚ç³»åˆ—ãªã®ã§ [seq_len, 3] -> (t, x, y) 3æ¬¡å…ƒ
gaze_seq = torch.tensor([[t, x, y] for (t, x, y), _ in matched_pairs], dtype=torch.float32)

# textä½ç½®: [seq_len, 2] -> (x, y) 2æ¬¡å…ƒ
text_seq = torch.tensor([[tx, ty] for (_, (word, tx, ty)) in matched_pairs], dtype=torch.float32)

# ä¾‹: æ–‡å­—ã”ã¨ã®è¦–ç·šã®ç†æƒ³æ»åœ¨æ™‚é–“ï¼ˆæ“¬ä¼¼çš„ã§ã‚‚OKï¼‰
importance = {
    "æ¯€": 1.0,
    "å—¤": 1.0,
}
target_times = []
for (_, (word, _, _)) in matched_pairs:
    value = importance.get(word, 0.3)  # ãªã‘ã‚Œã° 1.0
    target_times.append([value])

target_times = torch.tensor(target_times, dtype=torch.float32).unsqueeze(0)  # shape: [1, seq_len, 1]

# batchæ¬¡å…ƒè¿½åŠ  â†’ [1, seq_len, features] PyTorch ã®ãƒ†ãƒ³ã‚½ãƒ«ã«æ–°ã—ã„æ¬¡å…ƒã‚’è¿½åŠ ã™ã‚‹
gaze_seq = gaze_seq.unsqueeze(0)
text_seq = text_seq.unsqueeze(0)

class GazeTextEncoder(nn.Module):
    def __init__(self, hidden_dim=32):
        super().__init__()
        self.lstm_gaze = nn.LSTM(3, hidden_dim, batch_first=True)
        self.lstm_text = nn.LSTM(2, hidden_dim, batch_first=True)
        self.output_layer = nn.Linear(hidden_dim, 1)  # è¦–ç·šè¿½è·¡æ™‚é–“ã‚’äºˆæ¸¬ã™ã‚‹ãŸã‚ã®å‡ºåŠ›å±¤
        
    def forward(self, gaze_seq, text_seq):
        H_gaze, _ = self.lstm_gaze(gaze_seq)  # [1, seq_len, hidden_dim] å‡ºåŠ›
        H_text, _ = self.lstm_text(text_seq)  # [1, seq_len, hidden_dim]

        
        # ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³è¨ˆç®—ã®ãŸã‚ã« H_gaze ã‚’è»¢ç½®
       # H_gaze_transposed = H_gaze.transpose(1, 2)  # [batch_size, hidden_dim, g_len]
        
         # ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³è¨ˆç®—
        H_gaze_t = H_gaze.transpose(1, 2)  # [1, hidden_dim, seq_len]
        attn_scores = torch.bmm(H_text, H_gaze_t)  # [1, seq_len, seq_len]
        attn_weights = torch.softmax(torch.tanh(attn_scores), dim=-1)
        #attn_weights = torch.softmax(attn_scores, dim=-1)
        context = torch.bmm(attn_weights, H_gaze)  # [1, seq_len, hidden_dim]
        
        

        # è¦–ç·šè¿½è·¡æ™‚é–“ã®äºˆæ¸¬
        predicted_times = self.output_layer(context)  # [batch_size, t_len, 1]
        
        return predicted_times
    

# Step 5: ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã®æº–å‚™
model = GazeTextEncoder()
optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)
loss_fn = nn.MSELoss()


# Step 6: å­¦ç¿’ãƒ«ãƒ¼ãƒ—ï¼ˆä¾‹: 100 ã‚¨ãƒãƒƒã‚¯ï¼‰
for epoch in range(100):
    model.train()
    optimizer.zero_grad()
    outputs = model(gaze_seq, text_seq)
    loss = loss_fn(outputs, target_times)
    loss.backward()
    optimizer.step()

    if epoch % 10 == 0:
        print(f"Epoch {epoch}: Loss = {loss.item():.4f}")


# Step 7: æœ€çµ‚çš„ãªäºˆæ¸¬ã®è¡¨ç¤º
model.eval()
with torch.no_grad():
    predicted = model(gaze_seq, text_seq)
    print("\nğŸ“Š Predicted gaze times (per character):")
    for i, ((_, (word, _, _)), value) in enumerate(zip(matched_pairs, predicted[0])):
        print(f"{word}: {value.item():.3f}")
    print("attn_weights:", matched_pairs)